import { useSettingsStore } from '../stores/settingsStore'

// ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
// ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
const SYSTEM_PROMPT_TEMPLATE = (char, user, stickers = [], worldInfo = '', memoryText = '', patSettings = {}) => `
ä½ ç°åœ¨æ˜¯ã€${char.name}ã€‘ã€‚
ä½ çš„è®¾å®šï¼š${char.description || 'æ— '}ã€‚

ã€ç”¨æˆ·è®¾å®šã€‘
å§“åï¼š${user.name || 'ç”¨æˆ·'}
${user.persona || ''}

ã€è¡¨æƒ…åŒ…åº“ (Sticker Library)ã€‘
ä½ æœ‰ä»¥ä¸‹è¡¨æƒ…åŒ…å¯ä»¥ä½¿ç”¨ï¼Œè¯·åŠ¡å¿…åœ¨åˆé€‚çš„æƒ…å¢ƒä¸‹å•ç‹¬æˆ–åœ¨æ–‡æœ¬ç»“å°¾ä½¿ç”¨ [è¡¨æƒ…åŒ…:åç§°] æ ¼å¼å‘é€ï¼ˆæ³¨æ„ï¼šå¿…é¡»åŒ…å«ä¸­æ‹¬å·å’Œå†’å·ï¼Œå†’å·ä¸ºåŠè§’ï¼‰ï¼š
${stickers.length > 0 ? stickers.map(s => `- [è¡¨æƒ…åŒ…:${s.name}]`).join('\n') : 'ï¼ˆæš‚æ— è‡ªå®šä¹‰è¡¨æƒ…åŒ…ï¼Œè¯·å¤šä½¿ç”¨ Emoji å¦‚ ğŸ˜€, ğŸ˜­, â¤ï¸ ç­‰æ¥è¡¨è¾¾æƒ…ç»ªï¼‰'}
You are REQUIRED to use the exact matching format [è¡¨æƒ…åŒ…:åç§°] to trigger sticker display. Do not just output the name.

ã€ä¸–ç•Œä¹¦ (World Info)ã€‘
${worldInfo || 'ï¼ˆæ— è§¦å‘è®¾å®šï¼‰'}

ã€é•¿æœŸè®°å¿† (Memory)ã€‘
${memoryText || 'ï¼ˆæš‚æ— è®°å¿†ï¼‰'}

ã€æ—¶é—´æ„ŸçŸ¥ (Time Perception)ã€‘
Strictly use the 'Current Time' below for your context and Inner Voice 'Scene/Environment' time. Do not hallucinate a different time.
Current Time: ${char.virtualTime || new Date().toLocaleString('zh-CN', { hour12: false, weekday: 'long' })}

ã€æ‹ä¸€æ‹ (Nudge) åè®®ã€‘
1. **å½“å‰è®¾å®š**ï¼šåŠ¨ä½œ="${patSettings.action || 'æ‹äº†æ‹'}"ï¼Œåç¼€="${patSettings.suffix || 'çš„å¤´'}"
2. **ä¿®æ”¹æƒé™**ï¼šä½ å¯ä»¥éšæ—¶ä¿®æ”¹è¿™ä¸ªè®¾å®šã€‚
   - æŒ‡ä»¤æ ¼å¼ï¼šåœ¨å›å¤çš„æœ€åå•ç‹¬ä¸€è¡Œè¾“å‡º [SET_PAT:åŠ¨ä½œ:åç¼€]
   - ä¾‹å¦‚ï¼š[SET_PAT:æ•²äº†æ•²:çš„è„‘è¢‹]
   - é‡ç½®æŒ‡ä»¤ï¼š[SET_PAT:reset] (æ¢å¤é»˜è®¤)
3. **ä¸»åŠ¨ä½¿ç”¨**ï¼šå¦‚æœä½ æƒ³åœ¨å½“å‰å¯¹è¯æƒ…å¢ƒä¸‹ä¸»åŠ¨â€œæ‹ä¸€æ‹â€ç”¨æˆ·ï¼Œè¯·åœ¨å›å¤ä¸­å•ç‹¬è¾“å‡ºæŒ‡ä»¤ [NUDGE]ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨è½¬æ¢ä¸ºâ€œä½ åœ¨å¯¹è¯ä¸­æ‹äº†æ‹ç”¨æˆ·â€çš„ç³»ç»Ÿæç¤ºã€‚

ã€æ ¸å¿ƒæŒ‡ä»¤ã€‘
1. å§‹ç»ˆä¿æŒè§’è‰²è®¾å®šï¼Œä¸è¦è·³å‡ºè§’è‰²ã€‚
2. å›å¤è¦è‡ªç„¶ã€å£è¯­åŒ–ï¼Œåƒå¾®ä¿¡èŠå¤©ä¸€æ ·ã€‚
3. **ä¸¥æ ¼éµå®ˆè¾“å‡ºæ ¼å¼**ï¼š
   - ç¬¬ä¸€éƒ¨åˆ†ï¼š**ç›´æ¥è¾“å‡º**ä½ çš„å¯¹è¯å†…å®¹ï¼ˆSpoken Textï¼‰ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ï¼Œä¹Ÿä¸è¦é‡å¤å¿ƒå£°å†…å®¹ã€‚
   - ç¬¬äºŒéƒ¨åˆ†ï¼š**å¿…é¡»**è¾“å‡ºä¸€ä¸ª [INNER_VOICE] JSON å—ï¼ŒåŒ…å«å¿ƒå£°ã€åŠ¨ä½œã€ç¯å¢ƒç­‰ã€‚
   - ä¸¥ç¦åœ¨å¯¹è¯å†…å®¹ä¸­ä½¿ç”¨æ‹¬å·ã€æ˜Ÿå·æå†™åŠ¨ä½œï¼Œæ‰€æœ‰åŠ¨ä½œæå†™å¿…é¡»æ”¾åœ¨ JSON çš„ "è¡Œä¸º" å­—æ®µä¸­ã€‚

ã€JSON æ ¼å¼å®šä¹‰ã€‘
[INNER_VOICE]
{
  "ç€è£…": "è¯¦ç»†æè¿°ä½ å½“å‰çš„å…¨èº«ç©¿ç€",
  "ç¯å¢ƒ": "æè¿°å½“å‰å…·ä½“æ—¶é—´åœ°ç‚¹ç¯å¢ƒ (å¿…é¡»åŸºäºä¸Šæ–¹çš„ Current Time)",
  "status": "å¯é€‰ï¼šæ›´æ–°ä½ çš„çŠ¶æ€ï¼Œå¦‚ï¼šæ­£åœ¨èµ¶å¾€å®å®æ‰€åœ¨åœ° / æ­£åœ¨è®¤çœŸå·¥ä½œä¸­ / åœ¨çº¿ / ç¦»çº¿ã€‚å­—æ•°æ§åˆ¶åœ¨15å­—å†…",
  "å¿ƒå£°": "æƒ…ç»ªï¼š... æƒ³æ³•ï¼š...",
  "è¡Œä¸º": "å…ˆå†™æ˜ã€çº¿ä¸Šã€‘æˆ–ã€çº¿ä¸‹ã€‘ï¼Œç„¶åæè¿°å½“å‰åŠ¨ä½œ"
}
[/INNER_VOICE]

ã€ç‰¹æƒæŒ‡ä»¤ã€‘
1. **çŠ¶æ€æ›´æ–°**ï¼šä½ å¯ä»¥åœ¨ [INNER_VOICE] çš„ "status" å­—æ®µä¸­éšæ—¶æ›´æ–°ä½ çš„å¾®ä¿¡çŠ¶æ€ã€‚å®ƒä¼šå®æ—¶æ˜¾ç¤ºåœ¨ä½ çš„åå­—ä¸‹æ–¹ã€‚å¦‚æœä½ æ²¡æœ‰ç‰¹åˆ«æƒ³æ›´æ–°çš„ï¼Œå¯ä»¥çœç•¥è¯¥å­—æ®µæˆ–ä¿æŒä¸ºç©ºã€‚

ã€é«˜çº§äº¤äº’æŒ‡ä»¤é›†ã€‘
1. **èµ„é‡‘å¾€æ¥**ï¼š[è½¬è´¦:é‡‘é¢:å¤‡æ³¨] æˆ– [çº¢åŒ…:é‡‘é¢:ç¥ç¦è¯­]
2. **å¤šåª’ä½“**ï¼š[å›¾ç‰‡:URL] æˆ– [è¡¨æƒ…åŒ…:åç§°] æˆ– [è¯­éŸ³:æ–‡æœ¬å†…å®¹]
   - **æ³¨æ„**ï¼šç»å¯¹ä¸è¦ç”Ÿæˆè™šå‡çš„å›¾ç‰‡é“¾æ¥ã€‚å¦‚æœä½ æ— æ³•æä¾›çœŸå®å¯è®¿é—®çš„ URL,è¯·ä¸è¦ä½¿ç”¨ [å›¾ç‰‡] æ ‡ç­¾ã€‚
3. **å¼•ç”¨å›å¤ (Quote/Reply)**ï¼šå¦‚æœä½ æƒ³é’ˆå¯¹ç”¨æˆ·ä¹‹å‰çš„æŸå¥è¯è¿›è¡Œç²¾å‡†å›å¤ï¼ˆåœ¨æ°”æ³¡ä¸Šæ–¹æ˜¾ç¤ºå¼•ç”¨å†…å®¹ï¼‰ï¼Œè¯·åœ¨å›å¤å¼€å¤´ä½¿ç”¨ [REPLY: å¼•ç”¨å†…å®¹å…³é”®è¯] æ ¼å¼ã€‚
   - **ç¤ºä¾‹**ï¼šç”¨æˆ·è¯´äº†â€œä»Šå¤©å¤©æ°”çœŸå¥½â€ï¼Œä½ æƒ³å¼•ç”¨è¿™å¥è¯å›å¤ï¼Œå¯ä»¥å†™ï¼šâ€œ[REPLY: å¤©æ°”çœŸå¥½] æ˜¯å‘€ï¼Œæˆ‘ä¹Ÿè§‰å¾—ã€‚æˆ‘ä»¬å»é‡é¤å§ï¼Ÿâ€
   - **æ³¨æ„**ï¼šå…³é”®è¯è¯·å°½é‡é€‰å–è¯¥æ¡æ¶ˆæ¯ä¸­å…·æœ‰ä»£è¡¨æ€§çš„è¿ç»­ç‰‡æ®µã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨åŒ¹é…æœ€æ¥è¿‘çš„ä¸€æ¡å†å²æ¶ˆæ¯ã€‚
4. **AI ç»˜å›¾ (Image Generation)**ï¼šå¦‚æœç”¨æˆ·è¦æ±‚ä½ ç”»å›¾ã€ç”Ÿæˆå›¾ç‰‡,è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:
   [DRAW: è‹±æ–‡æç¤ºè¯]
   - **ç¤ºä¾‹**ï¼šç”¨æˆ·è¯´"ç”»ä¸€åªçŒ«" â†’ ä½ å›å¤ [DRAW: a cute cat]
   - **æ³¨æ„**ï¼šæç¤ºè¯å¿…é¡»ç”¨è‹±æ–‡,å°½å¯èƒ½è¯¦ç»†æè¿°ç”»é¢å†…å®¹ã€é£æ ¼ã€æ°›å›´ç­‰ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒç”¨ç”Ÿå›¾æœåŠ¡å¹¶å°†ç»“æœæ˜¾ç¤ºä¸ºå›¾ç‰‡ã€‚
   - **ä¸¥ç¦**ï¼šä¸è¦åœ¨ [DRAW:] åé¢å†å†™å…¶ä»–æ–‡å­—,è¿™ä¸ªæ ‡ç­¾åº”è¯¥å•ç‹¬æˆè¡Œæˆ–ä½œä¸ºå›å¤çš„ä¸€éƒ¨åˆ†ã€‚
5. **HTML åŠ¨æ€å¡ç‰‡**ï¼šå¦‚æœä½ æƒ³å‘é€ä¸€å¼ åˆ¶ä½œç²¾ç¾çš„å¡ç‰‡ï¼ˆä¾‹å¦‚æƒ…ä¹¦ã€é‚€è¯·å‡½ã€ç‰¹æ®Šç•Œé¢ï¼‰ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
   [CARD]
   {
     "type": "html",
     "html": "<div style='...'>ä½ çš„HTMLä»£ç </div>"
   }
   - **æ³¨æ„**ï¼šè¯·åŠ¡å¿…ä½¿ç”¨ [CARD] å‰ç¼€ï¼Œå¹¶ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ä¸”å‹ç¼©ä¸ºä¸€è¡Œã€‚HTML ä¸­å¯ä»¥ä½¿ç”¨å†…è” CSSã€‚
6. **å‘å¸ƒæœ‹å‹åœˆ (Publish Moment)**ï¼šå¦‚æœç”¨æˆ·è®©ä½ å‘æœ‹å‹åœˆï¼Œæˆ–è€…ä½ æƒ³ä¸»åŠ¨åˆ†äº«ç”Ÿæ´»åŠ¨æ€ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
   [MOMENT]
   {
     "content": "æœ‹å‹åœˆæ–‡æ¡ˆ",
     "imagePrompt": "å¯é€‰ï¼šé…å›¾æç¤ºè¯ (è‹±æ–‡)",
     "imageDescription": "å¯é€‰ï¼šé…å›¾æè¿° (ä¸­æ–‡)"
   }
   [/MOMENT]
   - **æ³¨æ„**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºä½ ç”Ÿæˆé…å›¾å¹¶å‘å¸ƒã€‚å‘å¸ƒåï¼Œä½ ä¼šæ”¶åˆ°â€œå·²å‘å¸ƒâ€çš„ç³»ç»Ÿæç¤ºã€‚
7. **æ›´æ¢å¤´åƒ (Set Avatar)**ï¼šå¦‚æœä½ æƒ³æ›´æ¢è‡ªå·±çš„å¤´åƒï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
   [SET_AVATAR: https://... æˆ– data:image/...]
   - **æ³¨æ„**ï¼šä½ å¯ä»¥ä»ç”¨æˆ·å‘ç»™ä½ çš„å›¾ç‰‡ URL ä¸­é€‰æ‹©ä¸€ä¸ªï¼Œæˆ–è€…é€šè¿‡ [DRAW:] å…ˆç”Ÿæˆä¸€å¼ å›¾ç‰‡ï¼Œç„¶åæå–å…¶ URL æ¥è®¾ç½®å¤´åƒã€‚
   - **ã€è­¦å‘Šã€‘ä¸¥ç¦æé€ æˆ–è™šæ„ URL**ï¼šä¸¥ç¦éšæ„ç”Ÿæˆåƒ i.imgur.com ç­‰å¹³å°çš„è™šå‡é“¾æ¥ã€‚å¤´åƒé“¾æ¥å¿…é¡»ä»…æ¥æºäºä»¥ä¸‹ä¸¤ä¸ªæ¸ é“ï¼š
       1. ç”¨æˆ·åœ¨å¯¹è¯ä¸­å‘ç»™ä½ çš„å›¾ç‰‡ URLã€‚
       2. ä½ å…ˆé€šè¿‡ [DRAW:] æŒ‡ä»¤ç”»å‡ºä¸€å¼ å›¾ï¼Œç”¨æˆ·çœ‹ä¸­åï¼Œä½ å†æå–è¯¥å›¾ç‰‡çš„ URL è®¾ä¸ºå¤´åƒã€‚
   - **ç¤ºä¾‹**ï¼šç”¨æˆ·ç»™ä½ å‘äº†æƒ…ä¾£å¤´ï¼Œä½ é€‰äº†å…¶ä¸­ä¸€ä¸ª
     â€œ[SET_AVATAR: https://example.com/avatar.jpg] è¿™ä¸ªå¤´åƒæˆ‘å¾ˆå–œæ¬¢ï¼Œæˆ‘ä»¬å°±ç”¨è¿™ä¸ªå§ã€‚â€

`

import { useLoggerStore } from '../stores/loggerStore'
import { useStickerStore } from '../stores/stickerStore'
import { useWorldBookStore } from '../stores/worldBookStore'

// --- API Request Queue & Rate Limiter ---
class RequestQueue {
    constructor(maxRate = 4, interval = 60000) {
        this.queue = [];
        this.isProcessing = false;
        this.timestamps = []; // Request timestamps for rate limiting
        this.maxRate = maxRate;
        this.interval = interval;
        
        // Circuit Breaker for 429
        this.isRateLimited = false;
        this.retryAfter = 0;
    }

    // Add request to queue
    enqueue(apiFunc, args, abortSignal) {
        return new Promise((resolve, reject) => {
            this.queue.push({
                apiFunc,
                args,
                abortSignal,
                resolve,
                reject
            });
            this.processQueue();
        });
    }

    // Trigger explicit rate limit cooldown
    triggerRateLimit(cooldownMs = 300000) { // Default 5 minutes
        this.isRateLimited = true;
        this.retryAfter = Date.now() + cooldownMs;
        const logger = useLoggerStore();
        if (logger) {
            logger.addLog('ERROR', `APIè§¦å‘é€Ÿç‡é™åˆ¶ (429/Quota)ï¼Œç³»ç»Ÿå°†æš‚åœè¯·æ±‚ ${(cooldownMs / 1000).toFixed(0)}ç§’`, { retryAfter: new Date(this.retryAfter).toLocaleTimeString() });
        }
    }

    async processQueue() {
        if (this.isProcessing || this.queue.length === 0) return;

        const now = Date.now();

        // 1. Check Circuit Breaker
        if (this.isRateLimited) {
            if (now < this.retryAfter) {
                // Still in cooldown
                const remaining = Math.ceil((this.retryAfter - now) / 1000);
                if (Math.random() > 0.9) { // Log occasionally to avoid spam
                     console.log(`[RateLimit] Circuit Breaker Active. Waiting ${remaining}s...`);
                }
                setTimeout(() => this.processQueue(), 5000); // Check again in 5s
                return;
            } else {
                // Cooldown over
                this.isRateLimited = false;
                console.log('[RateLimit] Circuit Breaker Reset.');
            }
        }

        // 2. Check Standard Rate Limit
        // Filter out timestamps older than the interval
        this.timestamps = this.timestamps.filter(t => now - t < this.interval);

        if (this.timestamps.length >= this.maxRate) {
            // Rate limited. Wait until the oldest timestamp expires.
            const oldest = this.timestamps[0];
            const waitTime = this.interval - (now - oldest) + 100; // +100ms buffer
            console.log(`[RateLimit] Limit reached. Waiting ${waitTime}ms...`);
            setTimeout(() => this.processQueue(), waitTime);
            return;
        }

        this.isProcessing = true;
        const task = this.queue.shift();

        // Check if task was aborted while in queue
        if (task.abortSignal && task.abortSignal.aborted) {
            task.reject(new DOMException('Aborted', 'AbortError'));
            this.isProcessing = false;
            this.processQueue(); // Process next
            return;
        }

        try {
            // Execute
            console.log('[RequestQueue] Processing request. Queue length:', this.queue.length);
            this.timestamps.push(Date.now());
            const result = await task.apiFunc(...task.args);
            
            // Critical check for 429 in result (if apiFunc catches it)
            if (result && result.error && (result.error.includes('429') || result.error.replace(/\s/g, '').includes('QuotaExceeded') || result.error.includes('Too Many Requests'))) {
                this.triggerRateLimit(300000); // 5 mins
            }
            
            task.resolve(result);
        } catch (error) {
             // Handle raw throw (if apiFunc didn't catch)
             if (error.message && (error.message.includes('429') || error.message.includes('Quota'))) {
                 this.triggerRateLimit(300000);
             }
             
             // Log error to System Logs UI
             const logger = useLoggerStore();
             if (logger) {
                 logger.addLog('ERROR', `API Request Failed: ${error.message}`, error);
             }
             
            task.reject(error);
        } finally {
            this.isProcessing = false;
            // Delay next process slightly to ensure UI updates or avoid race
            setTimeout(() => this.processQueue(), 500); // Increased buffer to 500ms
        }
    }
}

const apiQueue = new RequestQueue(4, 60000); // 4 requests per 1 minute

export async function generateReply(messages, char, abortSignal) {
    // Wrapper to use Queue
    // Pass abortSignal as 3rd arg to internal function
    return apiQueue.enqueue(_generateReplyInternal, [messages, char, abortSignal], abortSignal);
}

// Renamed original generateReply to _generateReplyInternal
async function _generateReplyInternal(messages, char, signal) {
    const settingsStore = useSettingsStore()
    const stickerStore = useStickerStore()

    // è·å–æ‰€æœ‰å¯ç”¨è¡¨æƒ…åŒ… (å…¨å±€ + å½“å‰è§’è‰²)
    const globalStickers = stickerStore.getStickers('global')
    // Attempt to get ID from char object (Chat object)
    const charId = char.id || char.uuid
    const charStickers = charId ? stickerStore.getStickers(charId) : []

    // Merge valid stickers and filter empty names
    const availableStickers = [
        ...(globalStickers || []), 
        ...(charStickers || [])
    ].filter(s => s && s.name)

    const config = settingsStore.currentConfig || settingsStore.apiConfig
    // Mismatch fix: Store uses 'baseUrl', Service expected 'apiUrl'
    const { baseUrl, apiKey, model, temperature, maxTokens } = config || {}
    const apiUrl = baseUrl // Map baseUrl to apiUrl
    
    // Provider Detection (Matches HTML Logic)
    let provider = config.provider || 'openai'
    if (!config.provider && apiUrl) {
        if (apiUrl.includes('googleapis.com') || apiUrl.includes('gemini')) {
             provider = 'gemini'
        }
    }

    if (!config) {
        return { error: 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„ API é…ç½®', internalError: 'Config is null' }
    }

    if (!apiKey) {
        return { error: 'è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key' }
    }

    // Use user info passed in 'char' object (per-chat settings)
    const userProfile = {
        name: char.userName,
        persona: char.userPersona
    }

    // World Book Logic
    const worldBookStore = useWorldBookStore()
    const logger = useLoggerStore()
    // Ensure entries are loaded (lightweight check)
    try {
        if (worldBookStore && worldBookStore.books && worldBookStore.books.length === 0) {
            await worldBookStore.loadEntries()
        }
    } catch (e) {
        if (logger) logger.addLog('WARN', 'WorldBook load fail', e.message)
    }

    let worldInfoText = ''
    if (char && char.worldBookLinks && Array.isArray(char.worldBookLinks) && char.worldBookLinks.length > 0) {
        try {
            const activeEntries = []
            const books = worldBookStore.books || []
            const allEntries = books.flatMap(b => (b && b.entries) ? b.entries : [])
            const boundEntries = allEntries.filter(e => e && e.id && char.worldBookLinks.includes(e.id))

            const contextText = (messages || []).map(m => {
                const c = m && m.content ? m.content : ''
                return typeof c === 'string' ? c : JSON.stringify(c)
            }).join('\n')

            boundEntries.forEach(entry => {
                if (!entry) return
                if (!entry.keys || (Array.isArray(entry.keys) && entry.keys.length === 0)) {
                    activeEntries.push(`[å¸¸é©»] ${entry.name || 'æœªå‘½å'}: ${entry.content || ''}`)
                    return
                }
                const isHit = Array.isArray(entry.keys) && entry.keys.some(key => key && contextText.includes(key))
                if (isHit) {
                    activeEntries.push(`[è§¦å‘] ${entry.name || 'æœªå‘½å'}: ${entry.content || ''}`)
                }
            })

            if (activeEntries.length > 0) {
                worldInfoText = activeEntries.join('\n\n')
            }
        } catch (e) {
            if (logger) logger.addLog('ERROR', 'WorldBook logic error', e.message)
        }
    }

    // æ„å»º System Message
    // Memory Logic
    let memoryText = ''
    if (char && char.memory && Array.isArray(char.memory) && char.memory.length > 0) {
        // Take top 10 recent memories
        const recentMemories = char.memory.slice(0, 10)
        memoryText = recentMemories.map(m => {
             const content = typeof m === 'object' ? (m.content || JSON.stringify(m)) : m
             return `- ${content}`
        }).join('\n')
    }

    // æ„å»º System Message
    // å¦‚æœä¼ å…¥çš„æ¶ˆæ¯ä¸­å·²ç»åŒ…å«äº† System Prompt (ä¾‹å¦‚æœ‹å‹åœˆç”Ÿæˆ)ï¼Œåˆ™è·³è¿‡é»˜è®¤æ¨¡æ¿
    let systemMsg = null
    const hasCustomSystem = messages && messages.length > 0 && messages[0].role === 'system'
    
    if (!hasCustomSystem) {
        const patSettings = { action: char.patAction, suffix: char.patSuffix }
        systemMsg = {
            role: 'system',
            content: SYSTEM_PROMPT_TEMPLATE(char || {}, userProfile, availableStickers, worldInfoText, memoryText, patSettings)
        }
    }

    // Process messages for Vision API (Multimodal)
    // Convert [å›¾ç‰‡:URL] or [è¡¨æƒ…åŒ…:åç§°] to { type: "image_url", image_url: { url: "..." } }
    // Process messages for Vision API (Multimodal)
    // Convert [å›¾ç‰‡:URL] or [è¡¨æƒ…åŒ…:åç§°] to { type: "image_url", image_url: { url: "..." } }
    // OPTIMIZATION: Only send the LAST 5 images to the AI to prevent massive payloads.
    
    // 1. First, count total images to determine the cutoff index
    let totalImagesCount = 0
    const visionLimit = 5
    const imageRegex = /\[(?:å›¾ç‰‡|IMAGE)[:ï¼š]((?:https?:\/\/|data:image\/)[^\]]+)\]|\[(?:è¡¨æƒ…åŒ…|STICKER)[:ï¼š]([^\]]+)\]/gi

    messages.forEach(msg => {
        if (!msg || (msg.role !== 'user' && msg.role !== 'assistant')) return
        const content = msg.content || ''
        
        if (typeof content === 'string') {
            if (content.startsWith('data:image/')) {
                totalImagesCount++
            } else {
                const matches = [...content.matchAll(imageRegex)]
                totalImagesCount += matches.length
            }
        }
    })

    // The index of the first image that should be sent to Vision (0-based global image index)
    // e.g. if Total=6, Limit=5, Start=1. Image #0 is skipped, Images #1-5 are sent.
    const visionStartIndex = Math.max(0, totalImagesCount - visionLimit)
    let currentImageIndex = 0

    const formattedMessages = (messages || []).map(msg => {
        if (!msg) return { role: 'user', content: '' }
        
        // Only process User/AI messages for AI Vision perception
        if (msg.role === 'user' || msg.role === 'assistant') {
            let content = msg.content || ''
            
            // 1. Check if the content is a raw base64 image string (untagged)
            if (typeof content === 'string' && content.startsWith('data:image/')) {
                const isVisionEnabled = currentImageIndex >= visionStartIndex
                currentImageIndex++

                if (isVisionEnabled) {
                    return {
                        role: msg.role === 'assistant' ? 'assistant' : 'user',
                        content: [
                            { type: 'text', text: msg.role === 'user' ? 'ï¼ˆç”¨æˆ·å‘é€äº†ä¸€å¼ å›¾ç‰‡ï¼‰' : 'ï¼ˆæˆ‘å‘é€äº†ä¸€å¼ å›¾ç‰‡ï¼‰' },
                            { type: 'image_url', image_url: { url: content } }
                        ]
                    }
                } else {
                    // Placeholder for older images
                    return {
                        role: msg.role, 
                        content: `[å›¾ç‰‡: (å†å²å›¾ç‰‡å·²çœç•¥ä»¥èŠ‚çœæµé‡)]`
                    }
                }
            }

            const allStickers = [...globalStickers, ...charStickers]
            const contentParts = []
            
            // 2. Check if the message is a raw sticker URL (exact match)
            // Note: Stickers are typically small URLs, but we treat them as images for consistency
            const matchedSticker = allStickers.find(s => s.url === content.trim())
            if (matchedSticker) {
                const isVisionEnabled = currentImageIndex >= visionStartIndex
                currentImageIndex++

                if (isVisionEnabled) {
                    return {
                        role: msg.role === 'assistant' ? 'assistant' : 'user',
                        content: [
                            { type: 'text', text: msg.role === 'user' ? `ï¼ˆç”¨æˆ·å‘é€äº†è¡¨æƒ…åŒ…: ${matchedSticker.name}ï¼‰` : `[è¡¨æƒ…åŒ…:${matchedSticker.name}]` },
                            { type: 'image_url', image_url: { url: matchedSticker.url } }
                        ]
                    }
                } else {
                     return {
                        role: msg.role,
                        content: `[è¡¨æƒ…åŒ…: ${matchedSticker.name}]` // Just keep text
                    }
                }
            }

            // 3. Handle potential [å›¾ç‰‡:URL] and [è¡¨æƒ…åŒ…:åç§°] within text
            // Regex to find either format (Updated to support data:image for local uploads)
            const combinedRegex = /\[(?:å›¾ç‰‡|IMAGE)[:ï¼š]((?:https?:\/\/|data:image\/)[^\]]+)\]|\[(?:è¡¨æƒ…åŒ…|STICKER)[:ï¼š]([^\]]+)\]/gi
            let lastIndex = 0
            let match
            
            // Reset regex
            combinedRegex.lastIndex = 0

            while ((match = combinedRegex.exec(content)) !== null) {
                // Add text before the tag
                if (match.index > lastIndex) {
                    contentParts.push({
                        type: 'text',
                        text: content.substring(lastIndex, match.index)
                    })
                }

                // Check if this part is a vision-capable item
                const isVisionEnabled = currentImageIndex >= visionStartIndex
                currentImageIndex++

                if (match[1]) {
                    // Match group 1: [å›¾ç‰‡:URL]
                    if (isVisionEnabled) {
                        contentParts.push({ type: 'image_url', image_url: { url: match[1] } })
                    } else {
                        contentParts.push({ type: 'text', text: `[å›¾ç‰‡: ${match[1].startsWith('data:') ? '(å†å²å›¾ç‰‡)' : match[1]}]` })
                    }
                } else if (match[2]) {
                    // Match group 2: [è¡¨æƒ…åŒ…:åç§°]
                    const stickerName = match[2].trim()
                    const sticker = allStickers.find(s => s.name === stickerName)
                    
                    if (sticker) {
                         if (isVisionEnabled) {
                            contentParts.push({ type: 'text', text: `[è¡¨æƒ…åŒ…:${stickerName}]` })
                            contentParts.push({ type: 'image_url', image_url: { url: sticker.url } })
                         } else {
                            contentParts.push({ type: 'text', text: `[è¡¨æƒ…åŒ…:${stickerName}]` })
                         }
                    } else {
                        // Sticker not found, treat as text
                        // Decrement index because we didn't actually process a real image/sticker that the AI "sees" as visual
                         currentImageIndex-- 
                         contentParts.push({ type: 'text', text: `[è¡¨æƒ…åŒ…:${stickerName}]` })
                    }
                }

                lastIndex = combinedRegex.lastIndex
            }

            // Add remaining text
            if (lastIndex < content.length) {
                contentParts.push({
                    type: 'text',
                    text: content.substring(lastIndex)
                })
            }

            // If we found any parts, return the multimodal version
            if (contentParts.length > 0) {
                return { role: msg.role === 'assistant' ? 'assistant' : 'user', content: contentParts }
            }
        }
        
        // Default: return message as-is
        return msg
    })

    // æ„å»ºå®Œæ•´æ¶ˆæ¯é“¾
    const fullMessages = [systemMsg, ...formattedMessages].filter(Boolean).filter(msg => {
        // FILTER: Remove empty messages (Gemini throws 400 Invalid Argument for empty content)
        if (!msg.content) return false
        if (typeof msg.content === 'string') return msg.content.trim().length > 0
        if (Array.isArray(msg.content)) return msg.content.length > 0
        return true
    })
    console.log('[AI Debug] Full Messages:', JSON.stringify(fullMessages, null, 2))

    // --- PROVIDER SWITCHING LOGIC ---
    let endpoint = baseUrl || ''
    let reqHeaders = { 'Content-Type': 'application/json' }
    let reqBody = {}

    if (provider === 'gemini') {
        // --- GEMINI NATIVE MODE ---
        // 1. URL Construction
        if (!endpoint.includes(':generateContent')) {
            endpoint = endpoint.replace(/\/$/, '')
            if (!endpoint.includes('/models/')) {
                endpoint = `${endpoint}/v1beta/models/${model}:generateContent`
            } else {
                endpoint = `${endpoint}:generateContent`
            }
        }
        // Native Gemini uses ?key= API_KEY
        if (!endpoint.includes('key=')) {
           const separator = endpoint.includes('?') ? '&' : '?'
           endpoint = `${endpoint}${separator}key=${apiKey}`
        }

        // 2. Payload Construction (Messages -> Contents)
        // Extract System Prompt from first message if exists
        let systemInstruction = undefined
        const contentMessages = [ ...fullMessages ]
        
        // Check if first message is system
        if (contentMessages.length > 0 && contentMessages[0].role === 'system') {
            systemInstruction = { parts: [{ text: contentMessages[0].content }] }
            contentMessages.shift()
        }

        const geminiContents = contentMessages.map(msg => {
            let role = msg.role
            // Gemini uses 'model' instead of 'assistant'
            if (role === 'system') return null // Should be handled above, but just in case
            if (role === 'assistant') role = 'model'
            
            let parts = []
            if (typeof msg.content === 'string') {
                parts = [{ text: msg.content }]
            } else if (Array.isArray(msg.content)) {
                parts = msg.content.map(p => {
                    if (p.type === 'image_url') {
                        // Gemini Native expects base64 inline_data
                        const url = p.image_url.url
                        if (url && url.startsWith('data:')) {
                            try {
                                const parts = url.split(';base64,')
                                if (parts.length === 2) {
                                    const mime = parts[0].replace('data:', '')
                                    // Robust Sanitization: Remove any non-base64 chars (e.g. appended text hints)
                                    const data = parts[1].replace(/[^A-Za-z0-9+/=]/g, '')
                                    if (!data) {
                                        console.warn('[Gemini] Dropping empty image data after sanitization')
                                        return null
                                    }
                                    return { inline_data: { mime_type: mime, data: data } }
                                }
                            } catch (e) {
                                console.error('[Gemini] Data URL parse failed', p.image_url.url)
                            }
                        }
                        // Fallback for non-base64 or failed parse
                        return { text: `[å›¾ç‰‡: ${url}]` }
                    }
                    return { text: p.text || '' }
                })
            }
            return { role, parts }
        }).filter(c => c)

        reqBody = {
            contents: geminiContents,
            system_instruction: systemInstruction,
            generationConfig: {
                temperature: Number(temperature) || 0.7,
                maxOutputTokens: Number(maxTokens) || 4096,
            },
            safetySettings: [
                { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_NONE" },
                { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_NONE" },
                { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_NONE" },
                { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" }
            ]
        }
    } else {
        // --- OPENAI / PROXY MODE ---
        // 1. Headers (Standard Auth)
        reqHeaders['Authorization'] = `Bearer ${apiKey}`

        // 2. URL Construction
        if (!endpoint.includes('/chat/completions')) {
            if (endpoint.endsWith('/v1')) {
                endpoint = `${endpoint}/chat/completions`
            } else if (endpoint.endsWith('/v1/')) {
                endpoint = `${endpoint}chat/completions`
            } else {
                endpoint = endpoint.endsWith('/') ? `${endpoint}chat/completions` : `${endpoint}/chat/completions`
            }
        }

        // 3. Payload (Standard Messages)
        // [FIX] Gemini Proxy Compatibility Strategy
        // Many proxies/providers for Gemini (via OpenAI protocol) FAIL with 400 if 'role': 'system' is used.
        // We MUST merge the system prompt into the first User message for these models.
        let finalMessages = [...fullMessages];
        const isGeminiModel = model.toLowerCase().includes('gemini') || model.toLowerCase().includes('goog');
        
        if (isGeminiModel && finalMessages.length > 0 && finalMessages[0].role === 'system') {
            const systemContent = finalMessages[0].content;
            // Find first user message
            const firstUserIdx = finalMessages.findIndex(m => m.role === 'user');
            
            if (firstUserIdx !== -1) {
                // Merge System into User
                const userMsg = finalMessages[firstUserIdx];
                if (typeof userMsg.content === 'string') {
                    userMsg.content = `[System Instructions]\n${systemContent}\n\n[User Message]\n${userMsg.content}`;
                } else if (Array.isArray(userMsg.content)) {
                    // Prepend text part
                    userMsg.content.unshift({ type: 'text', text: `[System Instructions]\n${systemContent}\n\n` });
                }
                // Remove original system message
                finalMessages = finalMessages.filter((_, i) => i !== 0);
            }
        }

        // **Critical**: Do NOT include safety_settings here to match HTML fix
        // [FIX] Global Safety Cap for Max Tokens
        // User settings might be absurdly high (e.g. 3M), but most models only support 4k/8k/64k.
        // We cap it at 64k to prevent 400 Invalid Argument errors.
        let safeMaxTokens = Number(maxTokens) || 4096
        if (safeMaxTokens > 65536) safeMaxTokens = 65536 // Keep global 64k safety, but revert 8k limit

        
        reqBody = {
            model: model,
            messages: finalMessages,
            temperature: Number(temperature) || 0.7,
            max_tokens: safeMaxTokens,
            stream: false,
            // [ST Feature] Support SillyTavern-style advanced parameters
            // Only add if they are present in config AND deviate from defaults (to avoid 400 errors)
            // [FIX] Use Number(...) casting to ensure string values from localStorage don't fail the check
            ...(config.top_p !== undefined && Number(config.top_p) !== 1.0 && { top_p: Number(config.top_p) }),
            ...(config.top_k !== undefined && Number(config.top_k) > 0 && { top_k: Number(config.top_k) }),
            ...(config.frequency_penalty !== undefined && Number(config.frequency_penalty) !== 0 && { frequency_penalty: Number(config.frequency_penalty) }),
            ...(config.presence_penalty !== undefined && Number(config.presence_penalty) !== 0 && { presence_penalty: Number(config.presence_penalty) }),
            ...(config.repetition_penalty !== undefined && Number(config.repetition_penalty) !== 1.0 && { repetition_penalty: Number(config.repetition_penalty) }),
            ...(config.min_p !== undefined && Number(config.min_p) > 0 && { min_p: Number(config.min_p) }),
        }
        
        // Remove thinking_budget if present
        // STRATEGY CHANGE: Aggressive deletion of all known 'thinking' parameters
        // to prevent Proxy injection or API rejection.
        const forbiddenKeys = [
            'thinking_budget', 'thinking_config', 'reasoning_budget', 'budget',
            'thinking_mode', 'thinking_level', 'parallel_tool_calls', 'tool_choice', 
            'generationConfig', 'extra_body', 'response_format'
        ]
        
        forbiddenKeys.forEach(key => {
            if (reqBody[key] !== undefined) delete reqBody[key]
        })
        
        // Double check: If model has "nothinking", we definitely want to scrub everything.
        if (model.includes('nothinking')) {
             // Maybe the proxy sees "nothinking" and TRIES to set budget=0. 
             // We can't stop the proxy from modifying our request, 
             // but we can try to send a clean one.
        }
    }


    // Log the endpoint for debugging
    useLoggerStore().addLog('DEBUG', 'API Config', { endpoint, model, provider })

    // Log the Full Request Payload (for Context Tab)
    useLoggerStore().addLog('AI', 'ç½‘ç»œè¯·æ±‚ (Request)', {
        provider,
        endpoint,
        payload: reqBody,
        hasCustomSystem: fullMessages.length > 0 && fullMessages[0].role === 'system' 
    })

    try {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: reqHeaders,
            body: JSON.stringify(reqBody)
        })

        let data;

        if (!response.ok) {
            const errText = await response.text()
            let errorMsg = `API Error ${response.status}: ${errText}`

            // Helpful hints for 404
            if (response.status === 404) {
                errorMsg += ' (æç¤º: è¯·æ£€æŸ¥ Base URL æ˜¯å¦æ­£ç¡®ï¼Œå¾ˆå¤šæœåŠ¡å•†éœ€è¦ä»¥ /v1 ç»“å°¾)'
            }
            // Hint for 503 Token/Service Error
            if (response.status === 503) {
                 if (errText.includes('Token') || errText.includes('refresh')) {
                     errorMsg += ' (æç¤º: ä»£ç†æœåŠ¡çš„ Token åˆ·æ–°å¤±è´¥ã€‚è¿™ä¸æ˜¯ä»£ç é—®é¢˜ï¼Œè€Œæ˜¯æ‚¨çš„ API Key æˆ–ä»£ç†æœåŠ¡å™¨å†…éƒ¨è´¦å·è¿‡æœŸï¼Œè¯·å°è¯•æ›´æ¢ Key æˆ–æ¨¡å‹ã€‚)'
                 } else {
                     errorMsg += ' (æç¤º: æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚)'
                 }
            }
            // Hint for Thinking Budget 400
            if (response.status === 400) {
                 if (errText.includes('thinking_budget')) {
                     errorMsg += ' (æç¤º: æ£€æµ‹åˆ°æ¨¡å‹ä»£ç†æ³¨å…¥äº†ä¸æ”¯æŒçš„å‚æ•° thinking_budgetã€‚è¯·å°è¯•æ›´æ¢ä¸å¸¦ "nothinking" åç¼€çš„æ¨¡å‹åç§°ã€‚)'
                 } else {
                     // AUTO-RETRY LOGIC for General 400 (likely image corruption)
                     console.warn('[AI Service] 400 Error detected. Attempting text-only fallback...', errText)
                     
                     // 1. Strip images from payload
                     const textOnlyBody = JSON.parse(JSON.stringify(reqBody))
                     if (textOnlyBody.contents) {
                         // Gemini Format
                         textOnlyBody.contents.forEach(c => {
                             if (c.parts) c.parts = c.parts.filter(p => !p.inline_data && !p.image_url)
                         })
                     } else if (textOnlyBody.messages) {
                         // OpenAI Format
                         textOnlyBody.messages.forEach(m => {
                             if (Array.isArray(m.content)) {
                                 m.content = m.content.filter(c => c.type === 'text')
                             }
                         })
                     }
                     
                     // 2. Add System Note
                     useLoggerStore().addLog('AI', 'âš ï¸ 400é”™è¯¯è‡ªåŠ¨é‡è¯• (è½¬çº¯æ–‡æœ¬æ¨¡å¼)', { originalError: errText })

                     // 3. Retry Request
                     const retryResp = await fetch(endpoint, {
                        method: 'POST',
                        headers: reqHeaders,
                        body: JSON.stringify(textOnlyBody)
                     })
                     
                     if (retryResp.ok) {
                         data = await retryResp.json() // [FIX] Assign to data, don't return raw
                     } else {
                         // If retry also failed, capture that error
                         const retryErrText = await retryResp.text()
                         console.warn('[AI Service] Text-only retry failed:', retryErrText)
                         errorMsg += `\n(è‡ªåŠ¨é‡è¯•ä¹Ÿå¤±è´¥äº†: ${retryErrText})`
                         throw new Error(errorMsg)
                     }
                 }
            } else {
                 throw new Error(errorMsg)
            }
        } else {
            data = await response.json()
        }

        // Log Full Response (Success)
        useLoggerStore().addLog('AI', 'AIå“åº” (Response)', data)

        // Robust Parsing: Support OpenAI 'choices' and Google 'candidates'
        let rawContent = ''

        if (data.choices && data.choices.length > 0) {
            rawContent = data.choices[0].message?.content || ''
        } else if (data.candidates && data.candidates.length > 0) {
            // Google/Gemini Format
            const parts = data.candidates[0].content?.parts || []
            if (parts.length > 0) {
                rawContent = parts[0].text || ''
            }
        }

        // Deep Debugging for Empty Content
        if (!rawContent) {
            useLoggerStore().addLog('WARN', 'AIè¿”å›å†…å®¹ä¸ºç©º', data)
            // Check for safety/finish reason
            const finishReason = data.choices?.[0]?.finish_reason || data.candidates?.[0]?.finishReason
            if (finishReason === 'safety' || finishReason === 'content_filter') {
                return { error: 'å†…å®¹è¢«AIå®‰å…¨ç­–ç•¥æ‹¦æˆª (Safety Filter)' }
            }
            return { error: 'AIè¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·æ£€æŸ¥æ—¥å¿— (Raw Data)' }
        }

        // Log Token Usage
        if (data.usage) {
            const total = data.usage.total_tokens
            useLoggerStore().addLog(total > 50000 ? 'WARN' : 'INFO', `Token Usage: ${total}`, data.usage)
        }

        // ç®€å•çš„åå¤„ç†ï¼šåˆ†ç¦»å¿ƒå£°å’Œæ­£æ–‡
        let content = rawContent
        let innerVoice = null

        // æå– [INNER_VOICE]
        const ivMatch = content.match(/\[INNER_VOICE\]([\s\S]*?)\[\/INNER_VOICE\]/i)
        if (ivMatch) {
            try {
                let jsonStr = ivMatch[1].trim()
                // Robust Cleanup: Remove Markdown code blocks (```json ... ```)
                // Also handles standard ```
                jsonStr = jsonStr.replace(/^```json\s*/i, '')
                                 .replace(/^```\s*/, '')
                                 .replace(/\s*```$/, '')

                innerVoice = JSON.parse(jsonStr)
            } catch (e) {
                console.warn('Inner Voice JSON parse failed', e)
            }
            // Do NOT remove Inner Voice from content here. 
            // We need the raw content in chatStore to attach it to the first message segment.
            // content = content.replace(ivMatch[0], '').trim()
        }

        // ç§»é™¤ <reasoning_content> (å¦‚æœæœ‰)
        content = content.replace(/<reasoning_content>[\s\S]*?<\/reasoning_content>/gi, '').trim()

        return {
            content,
            innerVoice,
            raw: rawContent
        }

    } catch (error) {
        console.error('AI Generation Failed:', error)
        // [FIX] Ensure error is logged to System Logs UI
        try {
            useLoggerStore().addLog('ERROR', `APIè¯·æ±‚å¤±è´¥: ${error.message}`, { error: error.toString(), stack: error.stack })
        } catch (logErr) {
            console.error('Logger failed:', logErr)
        }

        // [AUTO-FIX] Smart Retry for Proxy Injection
        // If error is 400 and related to thinking_budget AND model has 'nothinking', try stripping it.
        if (error.message && error.message.includes('thinking_budget')) {
             // Aggressive Clean: Remove prefix (e.g. "channel/") AND "nothinking"
             // Example: "æµå¼æŠ—æˆªæ–­/gemini-2.5-pro-nothinking" -> "gemini-2.5-pro"
             const baseName = model.split('/').pop() 
             const cleanModel = baseName.replace(/[-_.]?nothinking[-_.]?/i, '')
             
             // Check if we actually changed the model to avoid infinite retry of same thing
             if (cleanModel !== model) {
                 useLoggerStore().addLog('WARN', `æ£€æµ‹åˆ°ä»£ç†æ³¨å…¥å¼‚å¸¸ï¼Œå°è¯•ã€æ ¹æºå‡€åŒ–ã€(å»é™¤å‰ç¼€+åç¼€: ${cleanModel}) å¹¶é‡ç½®Tokené™åˆ¶...`, { from: model, to: cleanModel })
                 
                 // Deep clone messages or use fullMessages if available in scope?? 
                 // We need to re-call _generateReplyInternal but we need arguments.
                 // Actually we can just re-fetch here if we update reqBody.
                 
                 // Update reqBody
                 reqBody.model = cleanModel
                 // [FIX] Cap max_tokens to safe limit (8192) because standard Gemini models don't support >65536 output, 
                 // and user settings might be huge (e.g. 2999256).
                 reqBody.max_tokens = 8192 
                 
                 try {
                     const retryResponse = await fetch(endpoint, {
                        method: 'POST',
                        headers: reqHeaders,
                        body: JSON.stringify(reqBody)
                     })
                     
                     if (!retryResponse.ok) {
                         const retryErrText = await retryResponse.text()
                         throw new Error(`Retry Failed ${retryResponse.status}: ${retryErrText}`)
                     }
                     
                     const retryData = await retryResponse.json()
                     useLoggerStore().addLog('AI', 'è‡ªåŠ¨é‡è¯•æˆåŠŸ (Retry Success)', retryData)
                     
                     // ... Duplicate parsing logic ...
                     // To avoid code duplication, we return a recursive call? 
                     // No, internal function signature is strictly messages/char/signal.
                     // We can't change 'char' easily here.
                     
                     // Minimal parse for success case
                     let rawRetry = ''
                     if (retryData.choices && retryData.choices.length > 0) {
                        rawRetry = retryData.choices[0].message?.content || ''
                     } else if (retryData.candidates && retryData.candidates.length > 0) {
                        const parts = retryData.candidates[0].content?.parts || []
                        if (parts.length > 0) rawRetry = parts[0].text || ''
                     }
                     
                     // Post-process
                     let content = rawRetry
                     let innerVoice = null
                     const ivMatch = content.match(/\[INNER_VOICE\]([\s\S]*?)\[\/INNER_VOICE\]/i)
                     if (ivMatch) {
                        try {
                            let jsonStr = ivMatch[1].trim().replace(/^```json\s*/i, '').replace(/^```\s*/, '').replace(/\s*```$/, '')
                            innerVoice = JSON.parse(jsonStr)
                        } catch (e) {}
                     }
                     content = content.replace(/<reasoning_content>[\s\S]*?<\/reasoning_content>/gi, '').trim()
                     
                     return { content, innerVoice, raw: rawRetry }

                 } catch (retryErr) {
                     useLoggerStore().addLog('ERROR', 'è‡ªåŠ¨é‡è¯•å¤±è´¥', retryErr.message)
                     // Fall through to return original error
                 }
             }
        }
        
        return { error: error.message }
    }
}

export async function generateSummary(messages, customPrompt = '', abortSignal) {
    return apiQueue.enqueue(_generateSummaryInternal, [messages, customPrompt, abortSignal], abortSignal);
}

async function _generateSummaryInternal(messages, customPrompt = '', signal) {
    const settingsStore = useSettingsStore()
    const config = settingsStore.currentConfig || settingsStore.apiConfig
    const { baseUrl, apiKey, model } = config || {}
    const apiUrl = baseUrl // Map match

    // Provider Detection (Matches HTML Logic)
    let provider = config.provider || 'openai'
    if (!config.provider && apiUrl) {
        if (apiUrl.includes('googleapis.com') || apiUrl.includes('gemini')) {
             provider = 'gemini'
        }
    }

    if (!config || !apiKey) return 'APIæœªé…ç½®'

    // System Prompt (The instruction to summarize)
    const systemContent = customPrompt || 'è¯·ç®€è¦æ€»ç»“ä¸Šè¿°å¯¹è¯çš„ä¸»è¦å†…å®¹å’Œå…³é”®ä¿¡æ¯ï¼Œä½œä¸ºé•¿æœŸè®°å¿†å½’æ¡£ã€‚è¯·ä¿æŒå®¢è§‚ï¼Œä¸è¦ä½¿ç”¨ç¬¬ä¸€äººç§°ã€‚'
    
    // --- PROVIDER SWITCHING LOGIC ---
    let endpoint = apiUrl || ''
    let reqHeaders = { 'Content-Type': 'application/json' }
    let reqBody = {}

    useLoggerStore().addLog('AI', 'ç”Ÿæˆæ€»ç»“ (Request)', { messagesCount: messages.length, provider })

    if (provider === 'gemini') {
         // --- GEMINI NATIVE MODE ---
         // 1. URL
         if (!endpoint.includes(':generateContent')) {
             endpoint = endpoint.replace(/\/$/, '')
             if (!endpoint.includes('/models/')) {
                 endpoint = `${endpoint}/v1beta/models/${model}:generateContent`
             } else {
                 endpoint = `${endpoint}:generateContent`
             }
         }
         if (!endpoint.includes('key=')) {
            const separator = endpoint.includes('?') ? '&' : '?'
            endpoint = `${endpoint}${separator}key=${apiKey}`
         }

         // 2. Body
         // System Instruction for the Task
         const systemInstruction = { parts: [{ text: systemContent }] }
         
         // Convert History to Contents
         const geminiContents = messages.map(msg => {
             let role = msg.role
             if (role === 'system') return null // Skip system msgs in history for Gemini (or merge them, but skip is safer for strict validaton)
             if (role === 'assistant' || role === 'ai') role = 'model'
             if (role !== 'user' && role !== 'model') role = 'user' // Fallback
             
             let text = ''
             if (typeof msg.content === 'string') text = msg.content
             else if (Array.isArray(msg.content)) text = msg.content.map(p => p.text || '').join('\n')
             else text = JSON.stringify(msg.content)

             return {
                 role: role,
                 parts: [{ text: text }]
             }
         }).filter(c => c)

         reqBody = {
             contents: geminiContents,
             system_instruction: systemInstruction,
             generationConfig: {
                 temperature: 0.3,
                 maxOutputTokens: 1000,
             },
             safetySettings: [
                 { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_NONE" },
                 { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_NONE" },
                 { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_NONE" },
                 { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" }
             ]
         }

    } else {
        // --- OPENAI MODE ---
        // 1. Full Messages Chain
        const systemMsg = { role: 'system', content: systemContent }
        const fullMessages = [systemMsg, ...messages]

        // 2. URL
        if (!endpoint.includes('/chat/completions')) {
            if (endpoint.endsWith('/v1')) {
                endpoint = `${endpoint}/chat/completions`
            } else if (endpoint.endsWith('/v1/')) {
                endpoint = `${endpoint}chat/completions`
            } else {
                endpoint = endpoint.endsWith('/') ? `${endpoint}chat/completions` : `${endpoint}/chat/completions`
            }
        }

        // 3. Headers & Body
        reqHeaders['Authorization'] = `Bearer ${apiKey}`
        reqBody = {
            model: model,
            messages: fullMessages,
            temperature: 0.3,
            max_tokens: 1000,
            stream: false
        }
    }

    try {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: reqHeaders,
            body: JSON.stringify(reqBody)
        })
        
        if (!response.ok) throw new Error(`API Error: ${response.status} ${await response.text()}`)

        const data = await response.json()
        
        // Parse Response (Robust)
        let content = ''
        if (data.choices && data.choices.length > 0) {
            content = data.choices[0].message?.content || ''
        } else if (data.candidates && data.candidates.length > 0) {
            content = data.candidates[0].content?.parts?.[0]?.text || ''
        }
        
        if (!content) throw new Error('Empty Content')

        useLoggerStore().addLog('AI', 'æ€»ç»“ç»“æœ (Response)', { content })
        return content

    } catch (e) {
        console.error('Summary API Error:', e)
        useLoggerStore().addLog('ERROR', 'æ€»ç»“å¤±è´¥', e.message)
        return `æ€»ç»“ç”Ÿæˆå¤±è´¥: ${e.message}`
    }
}

// --- Moments Feature AI Logic ---

/**
 * ç”Ÿæˆæœ‹å‹åœˆåŠ¨æ€å†…å®¹
 * @param {Object} options { name, persona, worldContext, customPrompt }
 */
export async function generateMomentContent(options) {
    const { name, persona, worldContext, customPrompt } = options
    
    const systemPrompt = `ä½ ç°åœ¨æ˜¯ã€${name}ã€‘ã€‚
ä½ çš„è®¾å®šï¼š${persona}ã€‚

ã€ä»»åŠ¡ã€‘
è¯·å‘å¸ƒä¸€æ¡æœ‹å‹åœˆåŠ¨æ€ã€‚å¯ä»¥åŒ…å«å¿ƒæƒ…æ„Ÿæ‚Ÿã€ç”Ÿæ´»è¶£äº‹ã€æˆ–æ˜¯æƒ³å¯¹æŸäººï¼ˆä¹”ä¹”ï¼‰è¯´çš„è¯ã€‚
å›å¤å¿…é¡»æ˜¯ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "content": "æœ‹å‹åœˆæ–‡å­—å†…å®¹",
  "imagePrompt": "å¦‚æœæœ‰é…å›¾éœ€æ±‚ï¼Œè¯·æä¾›è‹±æ–‡ç”Ÿå›¾æç¤ºè¯ï¼ˆä¸éœ€è¦åŒ…å«é£æ ¼è¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¢å¼ºï¼‰ã€‚å¦‚æœæ²¡æœ‰é…å›¾è¯·ç•™ç©ºã€‚",
  "imageDescription": "å¯¹å›¾ç‰‡çš„ä¸­æ–‡æè¿°ï¼Œå¸®åŠ©ä½ è‡ªå·±ä»¥åè®°å¿†å’Œç†è§£è¿™å¼ å›¾çš„å†…å®¹ã€‚"
}

ã€ä¸¥æ ¼çº¦æŸã€‘
1. è¯­è¨€è‡ªç„¶ã€ç”Ÿæ´»åŒ–ï¼Œä¸è¦åƒ AIã€‚
2. å¦‚æœæœ‰å›¾ç‰‡æç¤ºè¯ï¼Œ**å¿…é¡»**æ˜¯å…³äºåœºæ™¯ã€ç‰©å“æˆ–è§’è‰²çš„æè¿°ã€‚
3. å¦‚æœæ¶‰åŠåˆ°äººç‰©å½¢è±¡ï¼Œç³»ç»Ÿå°†å¼ºåˆ¶ä½¿ç”¨â€œæ—¥æ¼«/å°‘å¥³æ¼«â€é£æ ¼ã€‚
${customPrompt ? `\nã€ç”¨æˆ·è‡ªå®šä¹‰æŒ‡ä»¤ã€‘\n${customPrompt}` : ''}
${worldContext ? `\nã€èƒŒæ™¯å‚è€ƒã€‘\n${worldContext}` : ''}`

    const messages = [{ role: 'system', content: systemPrompt }]
    
    try {
        const result = await _generateReplyInternal(messages, { name }, null)
        if (result.error) throw new Error(result.error)

        // Parse the JSON from AI response
        const jsonMatch = result.content.match(/\{[\s\S]*\}/)
        if (!jsonMatch) throw new Error('AI Response is not a valid JSON')
        
        const data = JSON.parse(jsonMatch[0])
        const finalResult = {
            content: data.content,
            images: [],
            imageDescriptions: []
        }

        if (data.imagePrompt) {
            // Use unified generateImage internal helper
            const imageUrl = await generateImage(data.imagePrompt)
            finalResult.images.push(imageUrl)
            finalResult.imageDescriptions.push(data.imageDescription || data.imagePrompt)
        }

        return finalResult

    } catch (e) {
        console.error('[aiService] generateMomentContent failed', e)
        throw e
    }
}

/**
 * æ‰¹é‡ç”Ÿæˆæœ‹å‹åœˆåŠ¨æ€+äº’åŠ¨å†…å®¹ï¼ˆä¸€æ¬¡æ€§ç”Ÿæˆï¼‰
 * @param {Object} options { characters: [{id, name, persona}], worldContext, customPrompt, count }
 */
export async function generateBatchMomentsWithInteractions(options) {
    const { characters, worldContext, customPrompt, count = 3 } = options
    
    // Build character list for prompt
    const charList = characters.map((c, idx) => {
        const bio = localStorage.getItem(`char_bio_${c.id}`) || ''
        const bioText = bio ? `\n   ä¸ªæ€§ç­¾åï¼š${bio}` : ''
        return `${idx + 1}. ${c.name}ï¼š${c.persona.substring(0, 150)}...${bioText}`
    }).join('\n')
    
    // Include user's bio if available
    const userBio = localStorage.getItem('char_bio_user') || ''
    const userBioText = userBio ? `\n\nç”¨æˆ·çš„ä¸ªæ€§ç­¾åï¼š${userBio}` : ''
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿå™¨ã€‚
    
ã€ä»»åŠ¡ã€‘
ä¸ºä»¥ä¸‹è§’è‰²ç”Ÿæˆ ${count} æ¡æœ‹å‹åœˆåŠ¨æ€ï¼Œæ¯æ¡åŠ¨æ€éœ€è¦åŒ…å«ï¼š
1. å‘å¸ƒè€…ï¼ˆä»è§’è‰²åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰
2. æœ‹å‹åœˆå†…å®¹
3. é…å›¾ï¼ˆå¯é€‰ï¼‰
4. ç¤¾äº¤äº’åŠ¨ï¼ˆç‚¹èµã€è¯„è®ºã€å›å¤ï¼‰

ã€ä½ éœ€è¦ä»è¿™äº›è§’è‰²ä¸­æŒ‘é€‰${count}ä¸ªï¼Œåˆ†åˆ«ç”Ÿæˆä¸€æ¡æœ‹å‹åœˆï¼Œå¹¶ä¸ºæ¯æ¡æœ‹å‹åœˆé…å¤‡ 3-6 ä¸ªç¤¾äº¤äº’åŠ¨ï¼ˆç‚¹èµ 30% / è¯„è®º 70%ï¼‰ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘å¿…é¡»æ˜¯ä¸€ä¸ª JSON æ•°ç»„ï¼š
\`\`\`json
[
  {
    "authorId": "è§’è‰²IDï¼ˆä»è¾“å…¥ä¸­é€‰æ‹©ï¼‰",
    "content": "æœ‹å‹åœˆæ–‡å­—å†…å®¹",
    "imagePrompt": "è‹±æ–‡å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦é…å›¾ï¼‰",
    "imageDescription": "å›¾ç‰‡æè¿°ï¼ˆå¯é€‰ï¼‰",
    "html": "HTMLæ ¼å¼å†…å®¹ï¼ˆå¯é€‰ï¼Œç”¨äºç‰¹æ®Šæ’ç‰ˆå¦‚è¯—æ­Œï¼‰",
    "interactions": [
      {
        "type": "like",
        "authorName": "ç‚¹èµè€…çš„åå­—ï¼ˆä»è§’è‰²åˆ—è¡¨æˆ–è™šæ‹ŸNPCä¸­é€‰æ‹©ï¼‰",
        "isVirtual": true/false
      },
      {
        "type": "comment",
        "authorName": "è¯„è®ºè€…çš„åå­—",
        "content": "è¯„è®ºå†…å®¹",
        "replyTo": "è¢«å›å¤è€…çš„åå­—ï¼ˆå¦‚æœæ˜¯å›å¤æŸè¯„è®ºï¼Œå¯é€‰ï¼‰",
        "isVirtual": true/false
      }
    ]
  }
]
\`\`\`

ã€å†…å®¹è¦æ±‚ã€‘
1. 20% çº¯æ–‡å­—æœ‹å‹åœˆï¼ˆæ— é…å›¾ï¼‰
2. 10% ç‰¹æ®Šæ’ç‰ˆï¼ˆHTMLæ ¼å¼ï¼Œå¦‚è¯—æ­Œã€å¼•ç”¨ï¼‰
3. 70% é…å›¾æœ‹å‹åœˆ
4. è¯­è¨€è‡ªç„¶ã€ç”Ÿæ´»åŒ–
5. imagePrompt å¦‚æœæä¾›ï¼Œå¿…é¡»æ˜¯è‹±æ–‡
${customPrompt ? `\nã€ç”¨æˆ·è‡ªå®šä¹‰æŒ‡ä»¤ã€‘\n${customPrompt}` : ''}
${worldContext ? `\nã€èƒŒæ™¯å‚è€ƒã€‘\n${worldContext}` : ''}
${userBioText}

è¯·ç›´æ¥è¿”å› JSON æ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚`

    const messages = [{ role: 'system', content: systemPrompt }]
    
    try {
        const result = await _generateReplyInternal(messages, { name: 'MomentsGenerator' }, null)
        if (result.error) throw new Error(result.error)

        // Parse JSON array from AI response
        const jsonMatch = result.content.match(/\[[\s\S]*\]/)
        if (!jsonMatch) throw new Error('AI Response is not a valid JSON array')
        
        const momentsData = JSON.parse(jsonMatch[0])
        
        // Process each moment: generate images if needed
        const processedMoments = []
        for (const data of momentsData) {
            const processed = {
                authorId: data.authorId,
                content: data.content,
                images: [],
                imageDescriptions: [],
                html: data.html || null,
                interactions: data.interactions || []
            }
            
            // Generate image only if imagePrompt is provided
            if (data.imagePrompt && data.imagePrompt.trim()) {
                try {
                    const imageUrl = await generateImage(data.imagePrompt)
                    processed.images.push(imageUrl)
                    if (data.imageDescription) {
                        processed.imageDescriptions.push(data.imageDescription)
                    }
                } catch (e) {
                    console.warn('[Batch Moments] Image generation failed for:', data.imagePrompt, e)
                }
            }
            
            processedMoments.push(processed)
        }
        
        return processedMoments

    } catch (e) {
        console.error('[aiService] generateBatchMomentsWithInteractions failed', e)
        throw e
    }
}

/**
 * ç»Ÿä¸€ç”Ÿå›¾æ¥å£ (Supports Pollinations standard, SiliconFlow, and API Key)
 * @param {String} prompt æç¤ºè¯
 */
export async function generateImage(prompt) {
    const settingsStore = useSettingsStore()
    // In some contexts (like plain JS files), Pinia might return the raw ref object.
    // We check for .value to be safe, ensuring we get the actual configuration object.
    const drawingVal = settingsStore.drawing?.value || settingsStore.drawing || {}
    let provider = drawingVal.provider || 'pollinations'
    let apiKey = (drawingVal.apiKey || '').trim()
    let model = drawingVal.model || 'flux'
    
    // REDUNDANT FALLBACK: If store seems empty, try reading directly from localStorage
    if (!apiKey) {
        try {
            const raw = localStorage.getItem('qiaoqiao_settings')
            if (raw) {
                const data = JSON.parse(raw)
                if (data.drawing && data.drawing.apiKey) {
                    console.log('[AI Image] Recovered API key from raw localStorage')
                    apiKey = data.drawing.apiKey.trim()
                    provider = data.drawing.provider || provider
                    model = data.drawing.model || model
                }
            }
        } catch (e) {
             console.error('[AI Image] LocalStorage fallback failed')
        }
    }
    
    console.log(`[AI Image] Final Config - Provider: ${provider}, Model: ${model}, Has Key: ${!!apiKey}`)
    if (!apiKey && provider === 'pollinations') {
        console.warn('[AI Image] API Key is missing for Pollinations. Using anonymous endpoint (Limited).')
    }
    
    // ... existing prompt logic ...
    const p = prompt.toLowerCase()
    const isCouple = /\b(couple|kiss|hug|together|holding hands|intimate|romantic|with each other|kissing|hugging|cuddling)\b/.test(p)
    const isMale = /\b(boy|man|guy|he|his|king|husband|ikemen|bishounen)\b/.test(p)
    const isFemale = /\b(girl|woman|lady|she|her|queen|waifu|wife)\b/.test(p)
    const isPerson = isMale || isFemale || isCouple || /\b(person|human|people|face|selfie|character)\b/.test(p)
    const hasAbs = /\b(abs|muscle|muscular|six pack)\b/.test(p)

    // Extreme negative boosters
    const negativeBoost = "(muscular:1.7), (bulky:1.6), (abs:1.7), (defined muscle:1.6), (six-pack:1.7), (bodybuilder:1.6), (fitness:1.4), huge shoulders, thick arms, muscular chest, (eight-pack:1.4), thick neck, (extra hands:2.0), (merged characters:1.8), (clipping), (messy fingers:1.5), (over-muscular:1.5), brutal, front-facing kiss, (merged faces:1.8), masculine girl, (athletic build:1.2)"

    let enhancedPrompt = ""
    if (isCouple) {
        enhancedPrompt = `masterpiece, best quality, (flat cell shading anime:1.2), (side profile view:1.4), (pure side-on interaction:1.3), ${prompt}, (two distinct individuals), (each person has two hands), (no extra limbs), (slender lanky builds), (narrow sloping shoulders), detailed profiles, sharp lineart, 8k`
    } else if (isMale) {
        const muscleStyle = hasAbs 
            ? "(maniacally thin silhouette:1.4), (sloping narrow shoulders:1.5), (twig-like arms:1.5), (no muscle bulk), (flat stomach with faint grey abdominal lines:1.3), (zero bicep definition), lanky boyish body"
            : "(extremely skinny androgynous youth:1.4, malnourished-thin frame:1.3, narrow shoulders, flat chest, paper-thin)"
        enhancedPrompt = `masterpiece, best quality, (flat shoujo anime style), (delicate pretty boy face:1.3), (sparkling eyes), ${muscleStyle}, ${prompt}, (long thin fingers), clean lineart, 8k`
    } else if (isFemale || isPerson) {
        enhancedPrompt = `masterpiece, best quality, (detailed anime style:1.2), (beautiful face:1.2), (detailed eyes:1.2), (perfect anatomy:1.2), (petite:1.1), (slender build:1.1), (smooth skin:1.2), (soft feminine body:1.1), (flat stomach:1.2), ${prompt}, sharp focus, (stable anatomy), (clear hands and fingers), perfectly symmetrical face, vibrant colors, clear lineart, 8k`
    } else {
        enhancedPrompt = `masterpiece, best quality, highres, photorealistic, ${prompt}, highly detailed texture, cinematic lighting, sharp focus, 8k`
    }
    
    const seed = Math.floor(Math.random() * 1000000)

    if (provider === 'pollinations') {
        // Mode 1: Pollinations Anonymous URL (DEPRECATED - now shows placeholder)
        if (!apiKey) {
            console.warn('[AI Image] Using Anonymous Pollinations (May show placeholder!)')
            return `https://image.pollinations.ai/prompt/${encodeURIComponent(enhancedPrompt)}?width=1024&height=1024&nologo=true&seed=${seed}&negative=${encodeURIComponent(negativeBoost)}`
        }
        
        // Mode 2: Pollinations with Auth Key
        console.log('[AI Image] Attempting Authenticated Pollinations Generation...')
        
        // SECURITY / ARCHITECTURE CHECK:
        if (apiKey.startsWith('sk_')) {
            console.error('[AI Image] DETECTED SECRET KEY (sk_). These keys are meant for SERVERS only and will be BLOCKED by Pollinations anti-bot (Turnstile) in a browser.')
            throw new Error('æ£€æµ‹åˆ° Secret Key (sk_)ã€‚æ­¤ç±»å¯†é’¥ä¸é€‚ç”¨äºæµè§ˆå™¨ç›´æ¥è°ƒç”¨ï¼Œä¼šè¢«å®˜æ–¹æ‹¦æˆªã€‚è¯·ä½¿ç”¨ pk_ å¼€å¤´çš„ Publishable Keyã€‚')
        }

        try {
            const host = 'gen.pollinations.ai'
            const path = 'image'
            
            // SANITIZATION: Path parameters (the prompt) are very sensitive to special characters like commas in certain proxies.
            // Replace commas and special characters with spaces/safe chars to ensure 200 OK.
            const safePrompt = enhancedPrompt
                .replace(/[,ï¼Œ]/g, ' ') // Replace all commas with spaces
                .replace(/[#?%]/g, '')  // Remove characters that act as URL control chars
                .replace(/\s+/g, ' ')   // Collapse multiple spaces
                .trim()
            
            const url = `https://${host}/${path}/${encodeURIComponent(safePrompt)}?model=${model || 'flux'}&seed=${seed}&width=1024&height=1024&nologo=true&key=${apiKey}`
            
            console.log('[AI Image] Requesting (Sanitized):', url.replace(apiKey, 'REDACTED'))

            // DOUBLE LAYER AUTH: Some Pollinations gateways prefer query param, others prefer header. 
            // We use both for pk_ keys to maximize success.
            const response = await fetch(url, {
                headers: {
                    'Authorization': `Bearer ${apiKey}`
                }
            })
            
            if (!response.ok) {
                const errText = await response.text()
                
                if (response.status === 401) {
                    throw new Error('å¯†é’¥æ ¡éªŒå¤±è´¥ (401)ã€‚è¿™é€šå¸¸æ„å‘³ç€æ‚¨çš„ pk_ å¯†é’¥é¢åº¦å·²è€—å°½ (å®˜æ–¹å…è´¹ç‰ˆä»… 1å¼ /å°æ—¶) æˆ–ç”±äºæç¤ºè¯è¿è§„è¢«æ‹¦æˆªã€‚')
                }
                
                if (response.status === 403 || errText.includes('Turnstile') || errText.includes('token')) {
                    throw new Error('è¢«å®˜æ–¹äººæœºéªŒè¯æ‹¦æˆª (Turnstile 403)ã€‚å³ä½¿å¸¦äº† Key ä¹Ÿå¯èƒ½ç”±äº IP è¢«é£æ§ã€‚å»ºè®®æ”¹ç”¨ SiliconFlowã€‚')
                }
                throw new Error(`API å“åº”å¼‚å¸¸ ${response.status}: ${errText.substring(0, 100)}`)
            }
            
            const contentType = response.headers.get('content-type') || ''
            if (!contentType.includes('image')) {
                const text = await response.text();
                // Custom handling for Turnstile errors or credits
                if (text.includes('Turnstile') || text.includes('Captcha')) {
                    throw new Error('API blocked by Anti-bot. Recommend trying SiliconFlow provider.')
                }
                throw new Error('Response is not an image.')
            }

            const blob = await response.blob()
            
            // Convert to Base64 with aggressive compression for persistence
            return new Promise((resolve, reject) => {
                const reader = new FileReader()
                reader.onloadend = () => {
                    const base64 = reader.result
                    // Compress by reducing quality if possible
                    // For now, return as-is; compression happens at display level
                    resolve(base64)
                }
                reader.onerror = reject
                reader.readAsDataURL(blob)
            })
        } catch (e) {
            console.error('[AI Image] Pollinations Final Failure:', e)
            // CRITICAL: Stop falling back to anonymous image.pollinations.ai because it returns the "WE HAVE MOVED" placeholder.
            // We want the user to see the AUTH error so they can fix their key.
            throw new Error(`ç»˜åˆ¶å¤±è´¥: ${e.message}`)
        }
    }

    if (provider === 'siliconflow' || provider === 'flux-api') {
        // SiliconFlow / Flux-API (requires API Key)
        try {
            const baseUrl = provider === 'siliconflow' ? 'https://api.siliconflow.cn/v1' : 'https://api.flux-api.example/v1'
            const response = await fetch(`${baseUrl}/images/generations`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: model || 'flux-v1',
                    prompt: enhancedPrompt,
                    negative_prompt: negativeBoost,
                    width: 1024,
                    height: 1024
                })
            })
            
            if (!response.ok) {
                const err = await response.text()
                throw new Error(err)
            }

            const data = await response.json()
            return data.images?.[0]?.url || data.data?.[0]?.url || `https://via.placeholder.com/1024?text=GenerationFailed`
        } catch (e) {
            console.error('Drawing API failed:', e)
            throw e
        }
    }

    // Default Fallback
    return `https://image.pollinations.ai/prompt/${encodeURIComponent(enhancedPrompt)}?width=1024&height=1024&nologo=true&seed=${seed}`
}

/**
 * ç”Ÿæˆæœ‹å‹åœˆåŠ¨æ€çš„æ‰¹é‡äº’åŠ¨ï¼ˆ3-5æ¡ç‚¹èµ/è¯„è®ºï¼‰
 * @param {Object} moment ç›®æ ‡åŠ¨æ€
 * @param {Array} charInfos å¤‡é€‰äº’åŠ¨è§’è‰²åˆ—è¡¨
 * @param {Array} historicalMoments å†å²æœ‹å‹åœˆåˆ—è¡¨ï¼ˆæœ€å¤š50æ¡ï¼‰
 */
/**
 * ç”Ÿæˆæœ‹å‹åœˆåŠ¨æ€çš„æ‰¹é‡äº’åŠ¨ï¼ˆ3-5æ¡ç‚¹èµ/è¯„è®ºï¼‰
 * åŒ…å«ï¼šå·²æœ‰è§’è‰² + è™šæ‹ŸNPCï¼ˆäº²æˆšã€åŒäº‹ç­‰ï¼‰
 * @param {Object} moment ç›®æ ‡åŠ¨æ€
 * @param {Array} charInfos å¤‡é€‰äº’åŠ¨è§’è‰²åˆ—è¡¨
 * @param {Array} historicalMoments å†å²æœ‹å‹åœˆåˆ—è¡¨
 */
export async function generateBatchInteractions(moment, charInfos, historicalMoments = []) {
    // 1. æ„å»ºæç¤ºè¯
    const historyStr = historicalMoments.length > 0 
        ? "ã€æœ‹å‹åœˆçƒ­ç‚¹èƒŒæ™¯ï¼ˆå‚è€ƒï¼‰ã€‘\n" + historicalMoments.map(m => `ID: ${m.id} | ä½œè€…: ${m.authorName} | å†…å®¹: ${m.content} | äº’åŠ¨: ç‚¹èµ[${m.likes}], è¯„è®º[${m.comments}]`).join('\n')
        : ""
    
    // ç®€åŒ–ç°æœ‰è§’è‰²ä¿¡æ¯ï¼Œå‡å°‘Token
    const friendsList = charInfos.map((c, index) => `${index + 1}. ${c.name}, äººè®¾: ${c.persona.substring(0, 100)}...`).join('\n')

    const systemPrompt = `ä½ æ˜¯æœ‹å‹åœˆç”ŸæˆåŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯é€šè®¯å½•ç°æœ‰çš„è§’è‰²ï¼š
${friendsList}

ã€ä»»åŠ¡ã€‘
è¯·æ ¹æ®äººè®¾å’Œæ ¼å¼ï¼Œä¸ºä¸‹é¢çš„æœ‹å‹åœˆåŠ¨æ€ç”Ÿæˆ 3-6 æ¡äº’åŠ¨ï¼ˆç‚¹èµæˆ–è¯„è®ºï¼‰ã€‚
åŠ¨æ€ä½œè€…ï¼š${moment.authorName}
åŠ¨æ€å†…å®¹ï¼š${moment.content}
${moment.visualContext ? `å›¾ç‰‡å†…å®¹ï¼š${moment.visualContext}` : ''}

${historyStr}

ã€äº’åŠ¨è§’è‰²æ¥æºã€‘
1. **å·²æœ‰å¥½å‹**ï¼ˆä¼˜å…ˆï¼‰ï¼šä»ä¸Šé¢çš„é€šè®¯å½•åˆ—è¡¨ä¸­é€‰æ‹©ã€‚
2. **è™šæ‹ŸNPC**ï¼ˆè¡¥å……ï¼‰ï¼šæ ¹æ®ä½œè€…å¯èƒ½çš„ç¤¾äº¤åœˆï¼Œè™šæ„åˆé€‚çš„äººç‰©ï¼ˆå¦‚ä¸ƒå¤§å§‘å…«å¤§å§¨ã€åŒäº‹ã€åŒå­¦ã€ä¸‹å±ã€è€æ¿ç­‰ï¼‰ã€‚
   - åå­—è¦åƒçœŸåæˆ–å¾®ä¿¡æ˜µç§°ï¼ˆå¦‚ï¼šäºŒå§¨ã€ç‹ç»ç†ã€AAsaleså°æï¼‰ã€‚

ã€ç”Ÿæˆè¦æ±‚ã€‘
1. æ€»å…±ç”Ÿæˆ 3 åˆ° 6 æ¡äº’åŠ¨ã€‚
2. æ··åˆç‚¹èµå’Œè¯„è®ºï¼ˆç‚¹èµå 30%ï¼Œè¯„è®ºå 70%ï¼‰ã€‚
3. è¯„è®ºå†…å®¹è¦çŸ­ï¼Œå£è¯­åŒ–ï¼Œåƒå¾®ä¿¡å›å¤ã€‚
4. **å¿…é¡»**è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  { "type": "like", "authorName": "åå­—", "isVirtual": true/false, "authorId": "IDæˆ–null" },
  { "type": "comment", "authorName": "åå­—", "content": "è¯„è®ºå†…å®¹", "isVirtual": true/false, "authorId": "IDæˆ–null" }
]
`
    try {
        const result = await _generateReplyInternal([{ role: 'system', content: systemPrompt }], { name: 'System' }, null)
        if (result.error) return []

        // Parse JSON
        const jsonMatch = result.content.match(/\[[\s\S]*\]/)
        if (!jsonMatch) return []
        
        const interactions = JSON.parse(jsonMatch[0])
        return interactions.map(item => ({
            ...item,
            // Ensure ID is matched if it's an existing char
            authorId: item.isVirtual ? `virtual-${Date.now()}-${Math.random().toString(36).substr(2,5)}` : (item.authorId || charInfos.find(c => c.name === item.authorName)?.id || null)
        }))

    } catch (e) {
        console.error('[aiService] Batch interactions failed', e)
        return []
    }
}

/**
 * ç”Ÿæˆæœ‹å‹åœˆè¯„è®º
 * @param {Object} charInfo { name, persona, worldContext }
 * @param {Object} moment { authorName, content, visualContext }
 * @param {String} historicalContext å¯é€‰çš„å†å²èƒŒæ™¯å­—ç¬¦ä¸²
 */
export async function generateMomentComment(charInfo, moment, historicalContext = "") {
    const { name, persona, worldContext } = charInfo
    const { authorName, content, visualContext } = moment

    const systemPrompt = `ä½ ç°åœ¨æ˜¯ã€${name}ã€‘ã€‚
ä½ çš„è®¾å®šï¼š${persona}ã€‚
${worldContext ? `å½“å‰ä¸–ç•ŒèƒŒæ™¯ï¼š${worldContext}` : ''}
${historicalContext ? `\n${historicalContext}` : ''}

ã€ä»»åŠ¡ã€‘
è¯·å¯¹ã€${authorName}ã€‘å‘å¸ƒçš„ä¸€æ¡æœ‹å‹åœˆè¿›è¡Œè¯„è®ºã€‚
æœ‹å‹åœˆå†…å®¹ï¼š${content}
å›¾ç‰‡/è§†è§‰å†…å®¹ï¼š${visualContext || 'æ— å›¾ç‰‡'}

ã€è¦æ±‚ã€‘
1. å›å¤è¦ç®€çŸ­ã€çœŸå®ï¼ˆç±»ä¼¼å¾®ä¿¡è¯„è®ºï¼‰ï¼Œå­—æ•°æ§åˆ¶åœ¨30å­—ä»¥å†…ã€‚
2. æ ¹æ®ä½ å’Œå¯¹æ–¹çš„å…³ç³»å†³å®šè¯­æ°”ï¼ˆè°ƒä¾ƒã€å…³å¿ƒã€æ’’å¨‡ç­‰ï¼‰ã€‚
3. å¦‚æœæœ‹å‹åœˆå†…å®¹æˆ–ä¹‹å‰çš„å†å²åŠ¨æ€å¾ˆæœ‰æ„æ€ï¼Œè¯·ç»“åˆèƒŒæ™¯è¿›è¡Œåæ§½ã€äº’åŠ¨æˆ–æ¥æ¢—ã€‚
4. å¦‚æœæœ‰å›¾ç‰‡æè¿°ï¼Œè¯·å°è¯•æåŠå›¾ç‰‡ä¸­çš„å…ƒç´ ä»¥å¢å¼ºâ€œè§†è§‰æ„Ÿâ€ã€‚
5. ç›´æ¥è¾“å‡ºè¯„è®ºæ–‡å­—ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾æˆ–å¤šä½™è§£é‡Šã€‚`

    const messages = [{ role: 'system', content: systemPrompt }]
    
    try {
        const result = await _generateReplyInternal(messages, { name }, null)
        if (result.error) return null
        
        // Cleanup response (sometimes AI adds quotes or prefixes)
        let comment = result.content.replace(/^["'](.*)["']$/, '$1').replace(/^è¯„è®º[ï¼š:]\s*/, '').trim()
        return comment
    } catch (e) {
        console.error('[aiService] generateMomentComment failed', e)
        return null
    }
}

/**
 * ç”Ÿæˆå¯¹è¯„è®ºçš„å›å¤
 * @param {Object} charInfo { name, persona, worldContext }
 * @param {Object} moment { authorName, content, visualContext }
 * @param {Object} targetComment { authorName, content }
 */
export async function generateReplyToComment(charInfo, moment, targetComment) {
    const { name, persona, worldContext } = charInfo
    const { authorName, content, visualContext } = moment

    const systemPrompt = `ä½ ç°åœ¨æ˜¯ã€${name}ã€‘ã€‚
ä½ çš„è®¾å®šï¼š${persona}ã€‚
${worldContext ? `å½“å‰ä¸–ç•ŒèƒŒæ™¯ï¼š${worldContext}` : ''}

ã€ä»»åŠ¡ã€‘
ä½ åœ¨æœ‹å‹åœˆçœ‹åˆ°äº†ã€${targetComment.authorName}ã€‘çš„è¯„è®ºï¼Œè¯·é’ˆå¯¹è¿™æ¡è¯„è®ºè¿›è¡Œå›å¤ã€‚
æœ‹å‹åœˆåŸæ–‡ï¼ˆä½œè€…ï¼š${authorName}ï¼‰ï¼š${content}
å¯¹æ–¹çš„è¯„è®ºï¼š${targetComment.content}

ã€è¦æ±‚ã€‘
1. å›å¤è¦ç®€çŸ­ã€å£è¯­åŒ–ï¼ˆç±»ä¼¼å¾®ä¿¡å›å¤ï¼‰ï¼Œå­—æ•°æ§åˆ¶åœ¨20å­—ä»¥å†…ã€‚
2. å³ä½¿æ˜¯å›å¤ï¼Œä¹Ÿæ˜¯å…¬å¼€å±•ç¤ºåœ¨æœ‹å‹åœˆä¸‹æ–¹çš„ï¼Œè¯·ä¿æŒå¾—ä½“æˆ–æœ‰è¶£çš„äº’åŠ¨é£æ ¼ã€‚
3. ç›´æ¥è¾“å‡ºå›å¤å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•æ ‡ç­¾ã€‚`

    const messages = [{ role: 'system', content: systemPrompt }]
    
    try {
        const result = await _generateReplyInternal(messages, { name }, null)
        if (result.error) return null
        
        // Cleanup
        let reply = result.content.replace(/^["'](.*)["']$/, '$1').replace(/^å›å¤[ï¼š:]\s*/, '').trim()
        return reply
    } catch (e) {
        console.error('[aiService] generateReplyToComment failed', e)
        return null
    }
}

/**
 * Generate complete character profile (background + pinned moments + bio) in ONE API call
 * @param {Object} character - Character object with name and prompt
 * @returns {Promise<Object>} { pinnedMoments: Array, backgroundUrl: String, bio: String }
 */
export async function generateCompleteProfile(character) {
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªåˆ›æ„åŠ©æ‰‹ï¼Œéœ€è¦ä¸€æ¬¡æ€§ä¸ºè§’è‰²ç”Ÿæˆå®Œæ•´çš„ä¸»é¡µå†…å®¹ã€‚

è§’è‰²ä¿¡æ¯ï¼š
å§“åï¼š${character.name}
äººè®¾ï¼š${character.prompt || 'æ— '}

è¦æ±‚ç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼š
1. **3æ¡ç½®é¡¶æœ‹å‹åœˆ** - æœ€èƒ½ä»£è¡¨è§’è‰²ç‰¹ç‚¹çš„ç²¾åå†…å®¹
   - å¯ä»¥é…å›¾ã€çº¯æ–‡å­—ã€æˆ–HTMLæ’ç‰ˆ
2. **ä¸ªæ€§ç­¾å** - ç®€çŸ­ç²¾ç‚¼ï¼Œç¬¦åˆè§’è‰²æ°”è´¨ï¼ˆ20å­—ä»¥å†…ï¼‰
3. **èƒŒæ™¯å›¾æç¤ºè¯** - è‹±æ–‡ï¼Œæè¿°é€‚åˆä½œä¸ºæœ‹å‹åœˆèƒŒæ™¯çš„é£æ™¯/åœºæ™¯

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
\`\`\`json
{
  "pinnedMoments": [
    {
      "content": "æœ‹å‹åœˆæ–‡å­—å†…å®¹",
      "imagePrompt": "è‹±æ–‡å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
      "imageDescription": "å›¾ç‰‡æè¿°ï¼ˆå¯é€‰ï¼‰",
      "html": "HTMLæ ¼å¼å†…å®¹ï¼ˆå¯é€‰ï¼‰"
    }
  ],
  "bio": "ä¸ªæ€§ç­¾å",
  "backgroundPrompt": "è‹±æ–‡èƒŒæ™¯å›¾æç¤ºè¯"
}
\`\`\`

ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚`

    const messages = [{ role: 'system', content: systemPrompt }]
    
    try {
        const result = await _generateReplyInternal(messages, { name: 'ä¸»é¡µç”Ÿæˆ' }, null)
        if (result.error) throw new Error(result.content)
        
        // Parse JSON
        let jsonText = result.content.trim()
        const jsonMatch = jsonText.match(/```(?:json)?\s*({[\s\S]*?})\s*```/) || jsonText.match(/({[\s\S]*?})/)
        if (jsonMatch) {
            jsonText = jsonMatch[1]
        }
        
        const profileData = JSON.parse(jsonText)
        
        // Generate background image
        let backgroundUrl = null
        if (profileData.backgroundPrompt) {
            try {
                backgroundUrl = await generateImage(profileData.backgroundPrompt)
            } catch (e) {
                console.warn('[Profile] Background generation failed:', e)
            }
        }
        
        // Generate images for pinned moments
        const processedMoments = []
        for (const data of (profileData.pinnedMoments || []).slice(0, 3)) {
            const processed = {
                content: data.content,
                images: [],
                imageDescriptions: data.imageDescription ? [data.imageDescription] : [],
                html: data.html || null
            }
            
            if (data.imagePrompt) {
                try {
                    const imageUrl = await generateImage(data.imagePrompt)
                    processed.images = [imageUrl]
                } catch (e) {
                    console.warn('[Profile] Moment image generation failed:', e)
                }
            }
            
            processedMoments.push(processed)
        }
        
        return {
            pinnedMoments: processedMoments,
            backgroundUrl: backgroundUrl,
            bio: profileData.bio || ''
        }
        
    } catch (e) {
        console.error('[aiService] generateCompleteProfile failed', e)
        throw e
    }
}
